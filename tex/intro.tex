\todo[inline]{
- Structure of this report, for academic readers you can skip eduROV.
}
The structure of this report are as follows: 

\section{Teleoperation}


\subsection{Applications}
\todo[inline]{
- hazardous areas, explosives removal, telemedicine

- where sending humans is costly and/or risky

- focus on moving robots / alignment

- master-slave control loop
}
Teleoperation of robots will become more and more common as the technology makes it possible for people to accomplish tasks in remote, inaccessible and hostile environments. The range of applications are long, space exploration, military missions, undersea operations and surgery are some of them.

Unmanned vehicles comes in a variety of configurations and can be divided into unmanned aerial vehicles (UAV), ground (UGV), underwater (UUV) where the latter is also sometimes referred to as a remotely operated vehicle (ROV).

\citep{Ricks2004} "There are many reasons to study teleoperation, especially from the standpoint of improving the user interface. Teleoperation can be the most effective way to control mobile robots because it is easy to implement and easy for people to understand. Teleoperation is also a very simple autonomy level that allows us to study the interface itself apart from the intelligence derived from autonomy."


\subsection{Telepresence}
\todo[inline]{
- meaning

- what effects it
}

Telepresence is defined as the perception of being present in a remote environment 

there are many factors that influence teleoperation performance, bandwith, time delay, framerate, two-dimensions, field of view and more. \citep{Chen2007}

Because of the nature of teleoperation the situational awareness and telepresence is compromised because of numerous factors. In a teleoperation controlled through video feed some of the influencing factors could be time latency, frame rates, missing frame of reference, two-dimensional views, field of view and more.

\citep{Chen2007} went through more than 150 papers checked different teleoperation factors and how they influence user performance.



\subsection{Time delay}
\todo[inline]{
- Latency and delay will be used to denote the same thing

- Sources of latency in teleoperation

- Video latency

- inefficient move and wait strategy
 
- cognitive workload

- has to remember what has been done (integral of the actions)
}

\missingfigure{Graphics showing the different stages in communication that contribute to the latency}

\missingfigure{Table showing summary of research on the effects of time delay on operator performance}

Time delay present a problem since the user has to remember what has already been done, and this does not match with the image they are seeing.

\citep{Chen2007} "Studies have also shown that high latency lags tend to reduce perceived telepresence"

\citep{Chen2007} "people are generally able to detect latency as low as $10-20$ ms [83]. Generally, when system latency is over about 1 s, the operators begin to switch their control strategy to a "move and wait" "

\citep{Matheson2013} "Even with a latency of only several seconds, tele-operation in a time-delayed environment, in particular for the task of basic driving, is a difficult and highly stressful task for humans (Sheridan, 1993; Wright, 2007). It results in high levels of cognitive workload (Lovi et al., 2010)."

"Arthur et al. [89] also found latency (ranging from 50 to 550 ms) to be a more important factor than FR (30, 15, or 10 fps) for their participants 3-D tracing task performance."

[A] principle to reduce cognitive workload is to maintain a correlation with commands issued by the operator and the expected result of those commands as observed by the movement of the robot and changes in the interface (Nielsen, Goodrich, \& Ricks, 2007, p. 936)

\citep{Appelqvist2007} "Because of the teleoperation delay, human drivers
tend to cause the vehicle to oscillate with their "correcting" steering commands" 

\citep{Ricks2004} "The mental load required to keep track of robot pose and compensate for delay adversely affects the operator's ability to effectively control the robot."

There seems to be a increase in completion time and failure rate as DOF increase


\subsection{Delay compensation}
\todo[inline]{
- LOA Level Of Automation
- increase situational awerness
- Predictive technology
}

\citep{Luck2006} "The results indicate that the higher the LOA, the better the performance in terms of both time and number of errors made, and also the more resistant to the degrading effects of latency."

\citep{Fong2001} "With manual control, performance is limited by the operator's motor skills and his ability to maintain situational awareness."

\citep{Chen2007} "For example, time delays as short as 170 ms affected driving performance. If these delays cannot be engineered out of the system, it is suggested that predictive displays or other decision support be provided to the operator."

displaying a generated 3d scene from remote images

egocentric vs ecocentric

There are many ways to mitigate the effects of teleoperation with video latency. By increasing the level of autonomy the operator would have to give less commands. A fully autonomous setup would require no user input and the negative effects of time delay would be completely eliminated.

\citep{Goodrich2001} Made a comparison between neglect and time delay and argued that adjustable autonomy could be used to increase the robot effectiveness. And also mentions that a more autonomous robot is required when longer time delays are present. On the other side he also mentiones that "as autonomy level increases, the breadth of tasks that can be handled by a robot decreases."

In some cases, autonomy is essential to accommodate for communication delays. \citep{Dorais1999}

The second possibility is to introduce predictor displays with phantom robots. In this setup the future behaviour of the robot is predicted from user input and the last know configuration of the robot. This is then shown as computer generated version, or phantom robot in real-time.

\citep{Chen2007} "Based on this and other experimental results, Sheridan [86] recommended that supervisory control and predictor displays be used to ameliorate the negative impact of time delays on teleoperation."

\citep{Chen2007} "predictive displays have been shown to be able to reduce task performance time by 50\%-150\% [68]"

The third option is present more information to the operator so that he or she has a better foundation to understand how user input would impact the future state of the robot. This could include showing graphs of the last inputs, or giving feedback when the user does something.

\citep{Miller2005} performed a test where they "Instead of predicting where the rover will be, we remind the operator of what they have told the rover to do by providing them with a streaming command indicator."

\section{Predictive technology}
\todo[inline]{
- comparison table in order of relevance

- can only be considered as an approximate value since very few report numerical values but instead use graphs
}

\missingfigure{Table showing summary on research into predictive displays and it's effects on helping operators}

\citep{Chen2007} "Woods et al. [16] suggested that achieving functional presence might be a more realistic goal for teleoperation user interface design. Functional presence occurs when the teleoperator receives sufficient perceptual cues to effectively conduct teleoperations"

Predictive displays will predict the future configuration based on user input and show real-time predicted configuration.

\subsection{Adjusted control}
\todo[inline]{
- dynamic equation, state equation and predicted state \citep{Zhang2017}
}

\citep{Lu2018} "Preliminary results revealed that the delay compensation aid can reduce operators workload while enhancing primary task performance."


\subsection{Superimposed predictive information}

\citep{Mathan1996} "predictive display superimposing directional
velocity information on the video display"

\subsection{3D graphic models}
\todo[inline]{
- capturing 3d data from scene and predicting the movement in that scene

- phantom robot

- mesh generation

- monocular SLAM : Monocular Simultaneous Location and Mapping
	- stereo
	- depth sensors
	- inertia sensors
    
- Vision-based structure from motion (SFM)
    - tracking
    
- augmented or virtual reality

\citep{Hu2015}: "However many tele-robotics tasks are in unknown, unstructured environments where advance CAD models are not available."
}

\citep{Burkert2004} "Those predictions are only possible if models of the geometry, kinematics, and dynamics of the remote scene are locally available."

Another approach is by combining visual tracking and image-based 3d rendering, creating a computer generated world and extrapolating what the camera would see next after it has gotten the current user commands. \citep{Hu2015} did this, but as they mentioned this relatively required smooth motion and advanced model generation algorithms.

Predictive displays can be used in conjugating with augmented reality (AR) or virtual reality (VR). The drawback with VR is that it requires extensive information about the remote location and computer knowledge and power because the location with the robot has the be reconstructed digitally. This is often used in cases where industrial robots are used. Here each of the joints and surrounding area can be precisely calculated. Telerobotic servicing with robotic arms with overlayed 3D grapical robots \citep{Kim1993}

\citep{Hu2016}: "In VR-based Predictive display (PD), instead of delayed visual feedback from the remote robot site, an immediately and predicted visual feedback is rendered from a graphics model in response to the operator's motion command" (...) "This is only applicable to known structured environments."

\citep{Ricks2004} tested a predictive display based with a phantom robot seen from a tethered perspective is placed together with the video feed in AR fashion,. This required a laser range finder to model the environment. The prediction were performed by using the known position and velocity of the robot and calculating the predicted position and orientation based on user input.

Problems of the above solutions is that they require a lot of information about the environment which again requires extra equipment and more advanced algorithms to process that data.


\subsection{Video manipulation}
\todo[inline]{
- Having stored local bigger images on cropping that image
}

Another way producing predictive displays is by recording 360 degrees video on a low frame rate and only displaying a smaller selection of this to the user. When the the camera or robot is moved the predicted section can be displayed immediately by moving the selection in that direction. \citep{Baldwin1999}


\section{Problem statement}

Can an easy to implement predictive display based on translational video and augmented reality phantom robot increase task completion effectiveness under teleoperation with time-delay?

- H1 a simple predictor display based on image transformation can 
 increase the operator performance
 
- H2 PD decrease the operator cognitive workload
 
\citep{Lu2018} Nice hypothesis

\section{Engage eduROV}

This master thesis and research performed were in conjunction with the Engage eduROV project. A software for handling video transmission and robot communication were developed and this were also used for research purposes in this thesis. A full descirption can be seen in chapter \ref{chpEdurov}

\missingfigure{Image of the eduROV submersible}