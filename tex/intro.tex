The structure of this report are as follows: in this chapter, the applications and challenges with teleoperation will be discussed. In addition, a walk trough of the most popular methods in predictive technology to combat time delay issues will be presented.

Chapter \ref{chpEdurov} is dedicated to the development of the python package named \textit{eduROV} that was created in conjunction with the Engage eduROV summer school project at Norwegian University of Science and Technology (NTNU). The developed software were also used in the main experiment of this report. For those only concerned in the predictive technology and relevant research, this chapter can be skipped.

Next, in chapter \ref{chpPredictive} the developed predictor display based on translation movement will be presented. It will explain how the movement of a robot is estimated and how predicted changes are visualized.

Lastly, in chapter \ref{chpMethod} through \ref{chpDiscussion} the method, results and discussion is presented. Only small sections of the code and recorded data is presented in the chapters, but the rest can be found in the appendix at page \pageref{appendix}. \textbf{TODO}

\section{Teleoperation}


\subsection{Applications}
Teleoperation of vehicles has gained popularity since it first became possible. This includes underwater, ground, aerial and space vehicles. The controlled vehcicle is referred to as a \emph{remotely operated vehicle} (ROV). There are many locations and tasks where ROV's are useful. These includes places that are to risky for people, like post disaster areas, underwater operations, space, conflict zones etc. It can also be that using humans is to costly or just impossible. Offshore maintenance and heavy duty mining are some of the tasks. The word \emph{robot} will be used interchangeably with ROV throughout this thesis.

In this report the focus has been on teleoperation by the means of camera feed from the ROV (slave), to the remotely human operator (master) and then control signals from operator to the ROV. This form of teleoperation can be effective because it's easy to implement and understand for the operator. Other forms of teleoperation can be without camera feed or by increasing the level of autonomy (LOA). This will not be any focus in this report.

In addition, only unmanned vehicles will be considered. Although a unmanned ground vehicle (UGV) has been used in the experiment, the findings can be applied to teleoperation of all types of vehicles, that be aerial, ground, underwater and space. It does however not apply to situations where the camera is in a fixed position and rotation. This configuration is often used in telemedicine \citep{Kumcu2017} or robot arm manipulation \citep{Bejczy1990}.

\subsection{Telepresence}

\citep{Draper1998} defined telepresence as \emph{"the perception of presence within a physically remote or simulated site"}. He also states that \emph{"telepresence is generally hypothesized to improve efficiency or reduce user workload"} and that telepresence is beneficial to mission performance.

\citep{Chen2007} went through 150 papers and checked different teleoperation factors and how they influence user performance. They found eight main factors; Field of view (FOV), orientation, camera viewpoint, depth perception, video quality and frame rate (FR), time delay, and motion. FOV describes the amount of environment that is visible in the video. Orientation (in the environment) can be difficult to perceive if there is mismatch or lack of information. Camera viewpoint is often \emph{egocentric} (robot view) or \emph{exocentric} (birds view) which can lead to tunneling or loss of true ground view respectively. Lack of depth perception can cause wrong estimation of distances and video quality can reduce target identification. Time delays effects are very task dependent but often cause reduced driving performance. Motion describes the situation where the operator itself is moving and can cause motion sickness.


\subsection{Time delay}
Among the factors mentioned above, time delay or \emph{latency} has been found to have big impacts one teleoperation performance \citep{Chen2007}. Chen also noted that latencies as low as $10-20$ ms can be detected by people. \citep{Arthur1993} found latencies (ranging from 50 to 550 ms) to be a more important factor than FR (30, 15, or 10 fps). 

Time delay introduces a situation where the operator's commands does not correspond to the visual feedback he or she is getting. Because of this human drivers tend to over steer and oscillate with their \emph{correcting} steering commands \citep{Appelqvist2007}. This increase the cognitive workload because the operator has to remember the input already given when giving new control commands \citep{Matheson2013}. And \citep{Ricks2004} found that the mental load required to keep track of the robot pose adversely affects the operator's ability to effectively control the robot. A principle of reducing the workload is therefore to maintain correlation between commands issued by operator and changes in the interface \citep{Nielsen2007}. 

A summary of some reports can be seen in table \ref{reviewPerf}. It shows the increase factor for different tasks and delay times. An increase factor of 1.40 is equal to a 40\% increase in task completion time. The actual detrimental effect of latency is very task dependent. In the table, the same increase factor of 1.5 can be found at 100ms for a needle-driving task, and in the robot car movement task at 2000ms.
Some argue that task completion time increase linearly with delay time \citep{Ando1999}, \citep{Lane2002}. While others experience an exponential increase \citep{Xu2014}.

\input{./tables/reviewPerf}

The reasons for time delay can be many and is not the focus in this report. An overview can be seen in figure \textbf{TODO}. Some of the factors are distance between robot and operator, equipment technology, transfer method, interference, video compression, control algorithms efficiency and many more.

\missingfigure{Graphics showing the different stages in communication that contribute to the latency}


\subsection{Delay compensation}
\todo[inline]{
- LOA Level Of Automation
- increase situational awerness
- Predictive technology
}

\citep{Luck2006} "The results indicate that the higher the LOA, the better the performance in terms of both time and number of errors made, and also the more resistant to the degrading effects of latency."

\citep{Fong2001} "With manual control, performance is limited by the operator's motor skills and his ability to maintain situational awareness."

\citep{Chen2007} "For example, time delays as short as 170 ms affected driving performance. If these delays cannot be engineered out of the system, it is suggested that predictive displays or other decision support be provided to the operator."

displaying a generated 3d scene from remote images

egocentric vs ecocentric

There are many ways to mitigate the effects of teleoperation with video latency. By increasing the level of autonomy the operator would have to give less commands. A fully autonomous setup would require no user input and the negative effects of time delay would be completely eliminated.

\citep{Goodrich2001} Made a comparison between neglect and time delay and argued that adjustable autonomy could be used to increase the robot effectiveness. And also mentions that a more autonomous robot is required when longer time delays are present. On the other side he also mentiones that "as autonomy level increases, the breadth of tasks that can be handled by a robot decreases."

In some cases, autonomy is essential to accommodate for communication delays. \citep{Dorais1999}

The second possibility is to introduce predictor displays with phantom robots. In this setup the future behaviour of the robot is predicted from user input and the last know configuration of the robot. This is then shown as computer generated version, or phantom robot in real-time.

\citep{Chen2007} "Based on this and other experimental results, Sheridan [86] recommended that supervisory control and predictor displays be used to ameliorate the negative impact of time delays on teleoperation."

\citep{Chen2007} "predictive displays have been shown to be able to reduce task performance time by 50\%-150\% [68]"

The third option is present more information to the operator so that he or she has a better foundation to understand how user input would impact the future state of the robot. This could include showing graphs of the last inputs, or giving feedback when the user does something.

\citep{Miller2005} performed a test where they "Instead of predicting where the rover will be, we remind the operator of what they have told the rover to do by providing them with a streaming command indicator."

\section{Predictive technology}
\todo[inline]{
- comparison table in order of relevance

- can only be considered as an approximate value since very few report numerical values but instead use graphs
}

\missingfigure{Table showing summary on research into predictive displays and it's effects on helping operators}

\citep{Chen2007} "Woods et al. [16] suggested that achieving functional presence might be a more realistic goal for teleoperation user interface design. Functional presence occurs when the teleoperator receives sufficient perceptual cues to effectively conduct teleoperations"

Predictive displays will predict the future configuration based on user input and show real-time predicted configuration.

\subsection{Adjusted control}
\todo[inline]{
- dynamic equation, state equation and predicted state \citep{Zhang2017}
}

\citep{Lu2018} "Preliminary results revealed that the delay compensation aid can reduce operators workload while enhancing primary task performance."


\subsection{Superimposed predictive information}

\citep{Mathan1996} "predictive display superimposing directional
velocity information on the video display"

\subsection{3D graphic models}
\todo[inline]{
- capturing 3d data from scene and predicting the movement in that scene

- phantom robot

- mesh generation

- monocular SLAM : Monocular Simultaneous Location and Mapping
	- stereo
	- depth sensors
	- inertia sensors
    
- Vision-based structure from motion (SFM)
    - tracking
    
- augmented or virtual reality

\citep{Hu2015}: "However many tele-robotics tasks are in unknown, unstructured environments where advance CAD models are not available."
}

\citep{Burkert2004} "Those predictions are only possible if models of the geometry, kinematics, and dynamics of the remote scene are locally available."

Another approach is by combining visual tracking and image-based 3d rendering, creating a computer generated world and extrapolating what the camera would see next after it has gotten the current user commands. \citep{Hu2015} did this, but as they mentioned this relatively required smooth motion and advanced model generation algorithms.

Predictive displays can be used in conjugating with augmented reality (AR) or virtual reality (VR). The drawback with VR is that it requires extensive information about the remote location and computer knowledge and power because the location with the robot has the be reconstructed digitally. This is often used in cases where industrial robots are used. Here each of the joints and surrounding area can be precisely calculated. Telerobotic servicing with robotic arms with overlayed 3D grapical robots \citep{Kim1993}

\citep{Hu2016}: "In VR-based Predictive display (PD), instead of delayed visual feedback from the remote robot site, an immediately and predicted visual feedback is rendered from a graphics model in response to the operator's motion command" (...) "This is only applicable to known structured environments."

\citep{Ricks2004} tested a predictive display based with a phantom robot seen from a tethered perspective is placed together with the video feed in AR fashion,. This required a laser range finder to model the environment. The prediction were performed by using the known position and velocity of the robot and calculating the predicted position and orientation based on user input.

Problems of the above solutions is that they require a lot of information about the environment which again requires extra equipment and more advanced algorithms to process that data.


\subsection{Video manipulation}
\todo[inline]{
- Having stored local bigger images on cropping that image
}

Another way producing predictive displays is by recording 360 degrees video on a low frame rate and only displaying a smaller selection of this to the user. When the the camera or robot is moved the predicted section can be displayed immediately by moving the selection in that direction. \citep{Baldwin1999}


\section{Problem statement}

Can an easy to implement predictive display based on translational video and augmented reality phantom robot increase task completion effectiveness under teleoperation with time-delay?

- H1 a simple predictor display based on image transformation can 
 increase the operator performance
 
- H2 PD decrease the operator cognitive workload
 
\citep{Lu2018} Nice hypothesis

\section{Engage eduROV}

This master thesis and research performed were in conjunction with the Engage eduROV project. A software for handling video transmission and robot communication were developed and this were also used for research purposes in this thesis. A full descirption can be seen in chapter \ref{chpEdurov}

\missingfigure{Image of the eduROV submersible}